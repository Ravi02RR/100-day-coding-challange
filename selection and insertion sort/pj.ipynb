{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error {\"errors\":[{\"errorCode\":\"PB-APIM-ERR-1002\",\"errorDescription\":\"Invalid Access Token\"}]}\n",
      "Error: 401 Client Error: Unauthorized for url: https://api.precisely.com/demographics-segmentation/v1/demographics/bylocation?latitude=35.0118&longitude=-81.9571\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "DEMOGRAPHY_URL = \"https://api.precisely.com/demographics-segmentation/v1/demographics/bylocation\"\n",
    "\n",
    "def get_demography_data(latitude, longitude, api_key):\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(DEMOGRAPHY_URL, params=params, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Error\", response.text)\n",
    "        response.raise_for_status()\n",
    "\n",
    "api_key = 'Y58vnO2TOA1rwN0InhrJLYAADvQsKm4p' \n",
    "latitude = float(input(\"Enter latitude: \"))\n",
    "longitude = float(input(\"Enter longitude: \"))\n",
    "\n",
    "try:\n",
    "    demography_data = get_demography_data(latitude, longitude, api_key)\n",
    "    print(json.dumps(demography_data, indent=4))\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Drone lidar survey of the San Juan Fault, Vancouver Island, September 2022\n",
      "Identifier (FileID): OTDS.102023.3157.2\n",
      "Identifier (DocID): {65A9D0B3-2836-4CFA-A685-CBF4A285E5E0}\n",
      "Bounding Box (WGS84) - Lower Corner: -123.881458654248 48.6114724880793\n",
      "Bounding Box (WGS84) - Upper Corner: -123.812815277922 48.6292087871735\n",
      "------------------------\n",
      "Title: Survey of a subtle scarp at Chon Kemin, Kyrgyzstan, July 2019\n",
      "Identifier (FileID): OTDS.102023.32643.4\n",
      "Identifier (DocID): {9E0330A6-FF2A-4A5A-85D8-689C92417F62}\n",
      "Bounding Box (WGS84) - Lower Corner: 76.5904742144722 42.8623492881219\n",
      "Bounding Box (WGS84) - Upper Corner: 76.6010195577865 42.8676929988822\n",
      "------------------------\n",
      "Title: Survey of a prominent thrust scarp at Chon Kemin, Kyrgyzstan, July 2019\n",
      "Identifier (FileID): OTDS.102023.32643.3\n",
      "Identifier (DocID): {960A5E02-CB8F-4FF6-9429-3388DC0A74CB}\n",
      "Bounding Box (WGS84) - Lower Corner: 76.5653372628732 42.8544413312498\n",
      "Bounding Box (WGS84) - Upper Corner: 76.5791798270853 42.8614594938215\n",
      "------------------------\n",
      "Title: Drone lidar survey of the eastern shore of Columbia Lake, East Kootenays\n",
      "Identifier (FileID): OTDS.102023.2955.1\n",
      "Identifier (DocID): {0A5AD51C-44E9-4EF2-B65E-689721DEA221}\n",
      "Bounding Box (WGS84) - Lower Corner: -115.855555579173 50.2586101108968\n",
      "Bounding Box (WGS84) - Upper Corner: -115.836858634686 50.2965317241418\n",
      "------------------------\n",
      "Title: Point clouds derived from satellite imagery, Turkmenistan, 2013-2014\n",
      "Identifier (FileID): OTDS.102023.32640.4\n",
      "Identifier (DocID): {A705E1D2-A523-4D91-91BE-1A5273460ED6}\n",
      "Bounding Box (WGS84) - Lower Corner: 55.8799532007281 38.4881065380429\n",
      "Bounding Box (WGS84) - Upper Corner: 57.0287299380215 39.0908477502815\n",
      "------------------------\n",
      "Title: Drone lidar and SfM survey of the XEOLXELEK-Elk Lake Fault, May 2021\n",
      "Identifier (FileID): OTDS.102023.3157.1\n",
      "Identifier (DocID): {2A8F9E29-A0C7-400E-8B30-4ED6A6FF0A09}\n",
      "Bounding Box (WGS84) - Lower Corner: -123.388534319801 48.524631936568\n",
      "Bounding Box (WGS84) - Upper Corner: -123.385934728638 48.5267281320569\n",
      "------------------------\n",
      "Title: Survey of scarps near the Lower Lake at Chon Aksu, Kyrgyzstan, July 2019\n",
      "Identifier (FileID): OTDS.102023.32643.2\n",
      "Identifier (DocID): {02B1E447-23DB-48CC-B9CE-776F3B27BC7D}\n",
      "Bounding Box (WGS84) - Lower Corner: 77.3844468512484 42.8385047188601\n",
      "Bounding Box (WGS84) - Upper Corner: 77.3990667881124 42.8419239173094\n",
      "------------------------\n",
      "Title: Survey of a scarp on a fan near Chon Aksu, Kyrgyzstan, July 2019\n",
      "Identifier (FileID): OTDS.102023.32643.1\n",
      "Identifier (DocID): {9C73EE72-4ED6-473E-BBE4-1BD750DA154E}\n",
      "Bounding Box (WGS84) - Lower Corner: 77.5081995158757 42.8337441872082\n",
      "Bounding Box (WGS84) - Upper Corner: 77.5159079191693 42.8402321465179\n",
      "------------------------\n",
      "Title: Point clouds derived from satellite imagery, Neyshabour, Iran,  2014\n",
      "Identifier (FileID): OTDS.102023.32640.3\n",
      "Identifier (DocID): {88C12C9E-50F9-4248-A378-813362B0BBE9}\n",
      "Bounding Box (WGS84) - Lower Corner: 58.7306974918771 36.0735895026737\n",
      "Bounding Box (WGS84) - Upper Corner: 59.096905042401 36.382642246763\n",
      "------------------------\n",
      "Title: Point clouds derived from satellite imagery, Sabzevar, Iran, 2013-2014\n",
      "Identifier (FileID): OTDS.102023.32640.2\n",
      "Identifier (DocID): {1CD34F3B-7358-4050-B402-B16A20F8AEE7}\n",
      "Bounding Box (WGS84) - Lower Corner: 56.9780056393616 36.1806820220229\n",
      "Bounding Box (WGS84) - Upper Corner: 57.778395065038 36.4538202734971\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "def get_topography_data(longitude, latitude):\n",
    "    bbox = f\"{longitude},{latitude},{longitude},{latitude}\"\n",
    "\n",
    "    base_url = \"https://portal.opentopography.org/geoportal/csw/discovery\"\n",
    "    params = {\n",
    "        \"Request\": \"GetRecords\",\n",
    "        \"Service\": \"CSW\",\n",
    "        \"Version\": \"2.0.2\",\n",
    "        \"resultType\": \"results\",\n",
    "        \"TypeNames\": \"csw:Record\",\n",
    "        \"ElementSetName\": \"full\",\n",
    "        \"BBOX\": bbox\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        parse_xml(response.content)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "def parse_xml(xml_content):\n",
    "    root = ElementTree.fromstring(xml_content)\n",
    "    namespace = {\"ns0\": \"http://www.opengis.net/cat/csw/2.0.2\", \"dc\": \"http://purl.org/dc/elements/1.1/\", \"ns3\": \"http://www.opengis.net/ows\"}\n",
    "\n",
    "    for record in root.findall(\".//ns0:Record\", namespaces=namespace):\n",
    "        title = record.find(\".//dc:title\", namespaces=namespace)\n",
    "        file_id = record.find(\".//dc:identifier[@scheme='urn:x-esri:specification:ServiceType:ArcIMS:Metadata:FileID']\", namespaces=namespace)\n",
    "        doc_id = record.find(\".//dc:identifier[@scheme='urn:x-esri:specification:ServiceType:ArcIMS:Metadata:DocID']\", namespaces=namespace)\n",
    "        lower_corner = record.find(\".//ns3:LowerCorner\", namespaces=namespace)\n",
    "        upper_corner = record.find(\".//ns3:UpperCorner\", namespaces=namespace)\n",
    "\n",
    "       \n",
    "        print(f\"Title: {title.text if title is not None else 'N/A'}\")\n",
    "        print(f\"Identifier (FileID): {file_id.text if file_id is not None else 'N/A'}\")\n",
    "        print(f\"Identifier (DocID): {doc_id.text if doc_id is not None else 'N/A'}\")\n",
    "        print(f\"Bounding Box (WGS84) - Lower Corner: {lower_corner.text if lower_corner is not None else 'N/A'}\")\n",
    "        print(f\"Bounding Box (WGS84) - Upper Corner: {upper_corner.text if upper_corner is not None else 'N/A'}\")\n",
    "        print(\"------------------------\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    longitude = - 85.3131 \n",
    "    latitude = 25.0961     \n",
    "    get_topography_data(longitude, latitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_elevation(lat, lon, api_key):\n",
    "    \"\"\"\n",
    "    Get elevation for specific latitude and longitude using Google Maps Elevation API.\n",
    "    \n",
    "    Parameters:\n",
    "    - lat (float): Latitude\n",
    "    - lon (float): Longitude\n",
    "    - api_key (str): Your Google Maps Elevation API key\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary with elevation data or error message\n",
    "    \"\"\"\n",
    "\n",
    "    endpoint = \"https://maps.googleapis.com/maps/api/elevation/json\"\n",
    "    params = {\n",
    "        \"locations\": f\"{lat},{lon}\",\n",
    "        \"key\": api_key\n",
    "    }\n",
    "    \n",
    "    response = requests.get(endpoint, params=params).json()\n",
    "    \n",
    "    if response.get('status') == \"OK\":\n",
    "        return response['results'][0]\n",
    "    else:\n",
    "        return {\"error\": response.get('status')}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your Google Maps Elevation API key here\n",
    "    API_KEY = \"YOUR_GOOGLE_MAPS_API_KEY\"\n",
    "    \n",
    "    # Test the function\n",
    "    latitude = float(input(\"Enter the latitude: \"))\n",
    "    longitude = float(input(\"Enter the longitude: \"))\n",
    "    \n",
    "    elevation_data = get_elevation(latitude, longitude, API_KEY)\n",
    "    \n",
    "    if \"error\" in elevation_data:\n",
    "        print(\"Error:\", elevation_data[\"error\"])\n",
    "    else:\n",
    "        print(f\"Elevation at ({latitude}, {longitude}): {elevation_data['elevation']} meters\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Results:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_google_results_for_location(lat, lon):\n",
    "    query = f\"topography, demography, and market trends at {lat}, {lon}\"\n",
    "    url = f\"https://www.google.com/search?q={query}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    search_results = []\n",
    "    \n",
    "    for g in soup.find_all('div', class_='tF2Cxc'):\n",
    "        title = g.find('h3')\n",
    "        if title:\n",
    "            title = title.text\n",
    "\n",
    "        link = g.find('a')\n",
    "        if link:\n",
    "            link = link['href']\n",
    "\n",
    "        description = g.find('span', class_='aCOpRe')\n",
    "        if description:\n",
    "            description = description.text\n",
    "\n",
    "        if title and link and description:\n",
    "            search_results.append((title, description, link))\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        lat = float(input(\"Enter the latitude: \"))\n",
    "        lon = float(input(\"Enter the longitude: \"))\n",
    "        results = fetch_google_results_for_location(lat, lon)\n",
    "        \n",
    "        print(\"\\nSearch Results:\\n\")\n",
    "        for index, (title, description, link) in enumerate(results, 1):\n",
    "            print(f\"Result {index}:\")\n",
    "            print(f\"Place Name (Assuming it's part of the title): {title}\")\n",
    "            print(f\"Description: {description}\")\n",
    "            print(f\"Link: {link}\")\n",
    "            print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.7.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy)\n",
      "  Downloading thinc-8.2.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.3.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 45.9/45.9 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting smart-open<7.0.0,>=5.2.1 (from spacy)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "     ---------------------------------------- 0.0/158.6 kB ? eta -:--:--\n",
      "     -------------------------- ----------- 112.6/158.6 kB 3.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 158.6/158.6 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 181.6/181.6 kB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.10.1-cp311-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=4.6.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Downloading confection-0.1.3-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ravi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Downloading spacy-3.7.2-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.1 MB 7.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.6/12.1 MB 5.9 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.6/12.1 MB 6.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.6/12.1 MB 6.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/12.1 MB 5.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.3/12.1 MB 5.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.3/12.1 MB 5.0 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/12.1 MB 4.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.4/12.1 MB 6.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.5/12.1 MB 5.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.8/12.1 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.4/12.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/12.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.9/12.1 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/12.1 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.5/12.1 MB 6.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.8/12.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.1/12.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.3/12.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.6/12.1 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.9/12.1 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.1/12.1 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.4/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.7/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.0/12.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.3/12.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.5/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.9/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.2/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.4/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.0/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.3/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.6/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.9/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.2/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.8/12.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/12.1 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.6/12.1 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.9/12.1 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "   ---------------------------------------- 0.0/395.8 kB ? eta -:--:--\n",
      "   ------------------------------ --------- 297.0/395.8 kB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 395.8/395.8 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.10.1-cp311-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/2.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/2.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.9/2.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/2.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/2.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.0/57.0 kB ? eta 0:00:00\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 389.1/479.7 kB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 479.7/479.7 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.1-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.4/1.5 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.5 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.9/1.5 MB 6.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.2/1.5 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 6.7 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.3-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.8/49.8 kB ? eta 0:00:00\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.6 MB 6.3 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.6/6.6 MB 5.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.8/6.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.1/6.6 MB 6.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.4/6.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.7/6.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 2.0/6.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.3/6.6 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.6/6.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.9/6.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.1/6.6 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.4/6.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.7/6.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.0/6.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.3/6.6 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.6/6.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.9/6.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.2/6.6 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.4/6.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.7/6.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.0/6.6 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.3/6.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.0/45.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading confection-0.1.3-py3-none-any.whl (34 kB)\n",
      "Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: cymem, wasabi, typing-extensions, tqdm, spacy-loggers, spacy-legacy, smart-open, murmurhash, langcodes, cloudpathlib, catalogue, blis, annotated-types, typer, srsly, pydantic-core, preshed, pydantic, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.3 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.4.2 pydantic-core-2.10.1 smart-open-6.4.0 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.1 tqdm-4.66.1 typer-0.9.0 typing-extensions-4.8.0 wasabi-1.1.2 weasel-0.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Results:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def fetch_google_results_for_location(lat, lon):\n",
    "    query = f\"topography, demography, and market trends at {lat}, {lon}\"\n",
    "    url = f\"https://www.google.com/search?q={query}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    search_results = []\n",
    "    \n",
    "    for g in soup.find_all('div', class_='tF2Cxc'):\n",
    "        title = g.find('h3')\n",
    "        if title:\n",
    "            title = title.text\n",
    "\n",
    "        link = g.find('a')\n",
    "        if link:\n",
    "            link = link['href']\n",
    "\n",
    "        description = g.find('span', class_='aCOpRe')\n",
    "        if description:\n",
    "            description = description.text\n",
    "            doc = nlp(description)  # Moved inside the condition\n",
    "            places = [ent.text for ent in doc.ents if ent.label_ == \"GPE\"]\n",
    "        else:\n",
    "            places = []\n",
    "\n",
    "        if title and link and description:\n",
    "            search_results.append({\n",
    "                \"title\": title,\n",
    "                \"description\": description,\n",
    "                \"link\": link,\n",
    "                \"places\": places\n",
    "            })\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        lat = float(input(\"Enter the latitude: \"))\n",
    "        lon = float(input(\"Enter the longitude: \"))\n",
    "        results = fetch_google_results_for_location(lat, lon)\n",
    "        \n",
    "        print(\"\\nSearch Results:\\n\")\n",
    "        for index, result in enumerate(results, 1):\n",
    "            print(f\"Result {index}:\")\n",
    "            print(f\"Title: {result['title']}\")\n",
    "            print(f\"Description: {result['description']}\")\n",
    "            print(f\"Link: {result['link']}\")\n",
    "            print(f\"Identified Places: {', '.join(result['places'])}\")\n",
    "            print(\"-\" * 50)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
